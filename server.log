/Users/jeremy/frog-adventure-game/lib/frog/adventure/web/llm_client.rb:4: warning: ostruct was loaded from the standard library, but will no longer be part of the default gems starting from Ruby 3.5.0.
You can add ostruct to your Gemfile or gemspec to silence this warning.
Puma starting in single mode...
* Puma version: 6.6.0 ("Return to Forever")
* Ruby version: ruby 3.4.4 (2025-05-14 revision a38531fd3f) +PRISM [arm64-darwin24]
*  Min threads: 0
*  Max threads: 5
*  Environment: development
*          PID: 36780
* Listening on http://127.0.0.1:4567
* Listening on http://[::1]:4567
Use Ctrl-C to stop
DEBUG: Querying LLM with prompt length: 1021
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1456 chars)
::1 - - [20/Jul/2025:19:49:01 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 8.1066
DEBUG: Querying LLM with prompt length: 1010
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1334 chars)
::1 - - [20/Jul/2025:19:49:10 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 8.1538
DEBUG: Querying LLM with prompt length: 1011
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1261 chars)
::1 - - [20/Jul/2025:19:49:18 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 7.2532
DEBUG: Querying LLM with prompt length: 1003
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1228 chars)
::1 - - [20/Jul/2025:19:49:26 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 7.3920
DEBUG: Querying LLM with prompt length: 1028
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1104 chars)
::1 - - [20/Jul/2025:19:49:33 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 6.8047
DEBUG: Querying LLM with prompt length: 1003
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1409 chars)
::1 - - [20/Jul/2025:19:49:42 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 8.6110
DEBUG: Querying LLM with prompt length: 1006
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1356 chars)
::1 - - [20/Jul/2025:19:49:53 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 10.2440
DEBUG: Querying LLM with prompt length: 1020
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1557 chars)
::1 - - [20/Jul/2025:19:50:04 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 10.5615
DEBUG: Querying LLM with prompt length: 1013
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1224 chars)
::1 - - [20/Jul/2025:19:50:13 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 9.0573
DEBUG: Querying LLM with prompt length: 1008
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1210 chars)
::1 - - [20/Jul/2025:19:50:24 -0500] "POST /api/frog/generate HTTP/1.1" 200 - 9.9993
DEBUG: Querying LLM with prompt length: 1266
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1898 chars)
::1 - - [20/Jul/2025:19:50:40 -0500] "POST /api/adventure/start HTTP/1.1" 200 - 15.7120
DEBUG: Querying LLM with prompt length: 1266
DEBUG: Sending request to Ollama...
DEBUG: Got response from Ollama: 200
DEBUG: Generated text (1558 chars)
::1 - - [20/Jul/2025:19:50:54 -0500] "POST /api/adventure/start HTTP/1.1" 200 - 13.5101
